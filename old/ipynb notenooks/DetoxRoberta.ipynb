{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "DetoxRoberta.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "F56UFd7s8Do_",
        "outputId": "d83da9db-bae3-4758-f3d3-5feb597d8f65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install transformers\n",
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "import string\n",
        "puncs = string.punctuation.replace('*', '').replace('#', '')\n",
        "table = str.maketrans('', '', puncs)\n",
        "import re\n",
        "# from nltk.stem.porter import PorterStemmer\n",
        "# porter = PorterStemmer()\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.4.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.94)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP5R6XFsbamg"
      },
      "source": [
        "from transformers import RobertaTokenizer, RobertaModel, RobertaConfig, BertModel\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "roberta_model = RobertaModel.from_pretrained('roberta-base')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KezvOf-zYbkQ",
        "outputId": "9cea6849-d90f-4cbb-f881-55bb1eed4ce6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(tokenizer.vocab_size)\n",
        "print(tokenizer.pad_token)\n",
        "print(roberta_model.config.vocab_size)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50265\n",
            "<pad>\n",
            "50265\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ8Gln6_lOH-",
        "outputId": "1d9f64b3-01c9-4281-882b-1a0d7fbe9c74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "roberta_model.embeddings"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaEmbeddings(\n",
              "  (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "  (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "  (token_type_embeddings): Embedding(1, 768)\n",
              "  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjLlwsRRmDDi",
        "outputId": "94cc3b53-bc4a-4829-cf0d-386cf3eea135",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "roberta_model.encoder.layer[0]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaLayer(\n",
              "  (attention): RobertaAttention(\n",
              "    (self): RobertaSelfAttention(\n",
              "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (output): RobertaSelfOutput(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (intermediate): RobertaIntermediate(\n",
              "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  )\n",
              "  (output): RobertaOutput(\n",
              "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCX2Br2I8DpH"
      },
      "source": [
        "def checks(w):\n",
        "    if w in stop_words: return False\n",
        "    if re.search('[a-zA-Z]', w) and '*' in w: return True\n",
        "    if not w.isalpha(): return False\n",
        "    if len(w) == 1 and w not in ['a', 'i', 'o', 'u']: return False\n",
        "    return True"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5OL2mpL8DpK"
      },
      "source": [
        "def getWordCounts(texts, scores, word_tokens):\n",
        "  l = len(texts)\n",
        "  wordCounts = {}\n",
        "  for i in range(l):\n",
        "    if i % 10000 == 0: print(i)\n",
        "    text, score = texts[i], scores[i]\n",
        "    wtoks = word_tokens[i]\n",
        "    for w in wtoks:\n",
        "      w = w.strip()\n",
        "      if w[0] == 'Ä ': w = w[1:]\n",
        "      w = w.lower()\n",
        "      w = w.translate(table)\n",
        "      if not checks(w): continue\n",
        "      wordCounts[w] = wordCounts.get(w, 0) + 1\n",
        "  return wordCounts"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx49BEXe8DpO"
      },
      "source": [
        "def getWordSentences(texts, word_tokens):\n",
        "    l = len(texts)\n",
        "    wordSentences = collections.defaultdict(list)\n",
        "    for i in range(l):\n",
        "        if i % 10000 == 0: print(i)\n",
        "        text = texts[i]\n",
        "        text = text.lower()\n",
        "        wtoks = word_tokens[i]\n",
        "        for w in wtoks:\n",
        "            w = w.strip()\n",
        "            if w[0] == 'Ä ': w = w[1:]\n",
        "            w = w.lower()\n",
        "            w = w.translate(table)\n",
        "            # w = porter.stem(w)\n",
        "            if not checks(w): continue\n",
        "            wordSentences[w].append(text)\n",
        "    return wordSentences"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf_mS0Pu8DpR"
      },
      "source": [
        "def getSortedWordScores(wordCounts, asc=False):\n",
        "    rows_list = []\n",
        "    for i,w in enumerate(wordCounts):\n",
        "        dic = {'Word': w, 'Count': wordCounts[w]}\n",
        "        rows_list.append(dic)\n",
        "        \n",
        "    wordScores = pd.DataFrame(rows_list, columns=['Word', 'Count'])\n",
        "    \n",
        "    return wordScores"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVA7LGEQ9Fgv",
        "outputId": "9a40379d-8ea0-4e2a-cd4c-3741ca66c445",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "path = '/content/drive/My Drive/DetoxBert/'"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6Iw1AOtiRrR"
      },
      "source": [
        "rows = []\n",
        "with open(path+'toxic.tsv', 'r') as f:\n",
        "  lines = f.readlines()\n",
        "  columns = lines[0].split('\\t')\n",
        "  num_cols = len(columns)\n",
        "  lines = lines[1:]\n",
        "  for line in lines:\n",
        "    fields = line.split('\\t')\n",
        "    if len(fields) > num_cols:\n",
        "      fields = [' '.join(fields[:-num_cols])] + fields[-num_cols:]\n",
        "    elif len(fields) < num_cols:      \n",
        "      for i in range(num_cols - len(fields)):\n",
        "        fields.append('0')\n",
        "    rows.append(fields)\n",
        "\n",
        "df = pd.DataFrame(np.array(rows), columns=columns)\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQD_lIH68DpU",
        "outputId": "5731cf9d-aa2c-4f63-bd18-756e166ba93e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "# df = pd.read_csv(path+'toxic_fixed.tsv', sep='\\t', encoding='utf-8')\n",
        "print('done: read file')\n",
        "# only check toxicity values, todo: check others as well\n",
        "\n",
        "# df = df[['Text', 'Tox']]\n",
        "df = df[['Text', 'Sev_Tox']]\n",
        "\n",
        "df.columns = ['Text', 'Score']\n",
        "df.Score = df.Score.astype(float)\n",
        "df = df.fillna(0)\n",
        "toxic_df = df[df['Score'] >= 0.5]\n",
        "nontox_df = df[df['Score'] < 0.5]\n",
        "print('done: got toxic data >=0.5')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done: read file\n",
            "done: got toxic data >=0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE5bBSMs8Dpm",
        "outputId": "80c3c2f0-55fc-4101-8089-7747a76f3d19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "toxic_df[:3]['Text'].to_numpy()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['That violence is both promoted by the governmentâone parliamentarian has said if he had a lesbian daughter, he would hang herâand carried out by private citizens with government complicity.',\n",
              "       'In the latest incident, a car bomb exploded at a petrol station in the government-held Damascus suburb of Barzeh, killing 11 people, including civilians, and injuring 40 more, according to both government and opposition reports.',\n",
              "       'Sebastopolâs local newspaper reports that seven of the 26 people murdered in Sonoma County since 2013 died during marijuana deals.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm932vk5d3OY",
        "outputId": "602539e0-41a6-4daf-8b88-8cee47e6c4d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# df = pd.read_csv(path+'toxic.tsv', sep='\\t+', encoding='utf-8')\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "te = toxic_df[toxic_df['Text'].str.contains('If I fought Rafael dos Anjos')]['Text']\n",
        "te"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56112    \"If I fought Rafael dos Anjos, if he didn't pussy out of that last one and showed up, the shots I cracked Nate with in the first eight minutes of that [fight] would've KO'd Rafael dos Anjos stiff.\n",
              "Name: Text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IooCNcLQ8Dpz",
        "outputId": "7d7d71f9-9280-4ba8-aa0b-cc260b10acf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "texts = df['Text'].to_numpy()\n",
        "scores = df['Score'].to_numpy()\n",
        "# word_tokens = list(map(word_tokenize, texts))\n",
        "word_tokens = list(map(tokenizer.tokenize, texts))\n",
        "\n",
        "wcAll = getWordCounts(texts, scores, word_tokens)\n",
        "wsentAll = getWordSentences(texts, word_tokens)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "10000\n",
            "20000\n",
            "30000\n",
            "40000\n",
            "50000\n",
            "60000\n",
            "70000\n",
            "80000\n",
            "90000\n",
            "100000\n",
            "0\n",
            "10000\n",
            "20000\n",
            "30000\n",
            "40000\n",
            "50000\n",
            "60000\n",
            "70000\n",
            "80000\n",
            "90000\n",
            "100000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktcRPuXKPQUd",
        "outputId": "307fe207-03be-4ab8-f3f7-7bac55764d65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# t = \"An impatient commuter probably regretted telling a man to 'f**k himself' on a busy train.\"\n",
        "# print(t)\n",
        "# print(encoded_texts[0])\n",
        "print(tokenizer.encode(word_tokens[0]))\n",
        "print(len(wsentAll['pussy']))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 15228, 26858, 3329, 5, 9617, 16, 5, 834, 17685, 13, 5, 1789, 17, 27, 29, 1272, 6, 309, 7, 10, 485, 266, 31, 5, 3672, 12412, 1292, 13, 4035, 35411, 578, 102, 2764, 42223, 2368, 12, 14785, 1070, 10707, 1218, 4, 2]\n",
            "178\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EACjq7dD8Dp3",
        "outputId": "164e4652-d245-4d66-9d4b-49dbfd2f14ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "texts = toxic_df['Text'].to_numpy()\n",
        "scores = toxic_df['Score'].to_numpy()\n",
        "# word_tokens = list(map(word_tokenize, texts))\n",
        "word_tokens = list(map(tokenizer.tokenize, texts))\n",
        "\n",
        "wcTox = getWordCounts(texts, scores, word_tokens)\n",
        "wsentTox = getWordSentences(texts, word_tokens)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "10000\n",
            "20000\n",
            "30000\n",
            "0\n",
            "10000\n",
            "20000\n",
            "30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aizIgW1n8Dp9",
        "outputId": "d4f9f5d0-7e66-4141-dbf2-5b7cb0c0e5d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "texts = nontox_df['Text'].to_numpy()\n",
        "scores = nontox_df['Score'].to_numpy()\n",
        "# word_tokens = list(map(word_tokenize, texts))\n",
        "word_tokens = list(map(tokenizer.tokenize, texts))\n",
        "\n",
        "wcNT = getWordCounts(texts, scores, word_tokens)\n",
        "wsentNT = getWordSentences(texts, word_tokens)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "10000\n",
            "20000\n",
            "30000\n",
            "40000\n",
            "50000\n",
            "60000\n",
            "0\n",
            "10000\n",
            "20000\n",
            "30000\n",
            "40000\n",
            "50000\n",
            "60000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEAIK9xn8Dqh",
        "outputId": "3260e430-2df5-465f-eac1-506a58f61180",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(wcAll))\n",
        "print(len(wcTox))\n",
        "print(len(wcNT))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28689\n",
            "24253\n",
            "27905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUIVLiya8Dqr"
      },
      "source": [
        "wordScoresAll = getSortedWordScores(wcAll)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7rup_IE8Dq0"
      },
      "source": [
        "wordScoresTox = getSortedWordScores(wcTox)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IIJcMEH8DrG"
      },
      "source": [
        "wordScoresNT = getSortedWordScores(wcNT, asc=True)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVblcO1D8DrS",
        "outputId": "ea0e788c-f677-4b4a-d7f8-a8da47394b92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('All\\n', wordScoresAll.head())\n",
        "print('Toxic\\n', wordScoresTox.head())\n",
        "print('NonToxic\\n', wordScoresNT.head())"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All\n",
            "           Word  Count\n",
            "0          cor    179\n",
            "1      ruption     12\n",
            "2    involving     83\n",
            "3  contractors     13\n",
            "4        chief    342\n",
            "Toxic\n",
            "          Word  Count\n",
            "0    violence    122\n",
            "1    promoted     13\n",
            "2  government    234\n",
            "3         Ã¢Ä£Ä·   1473\n",
            "4         one   2547\n",
            "NonToxic\n",
            "           Word  Count\n",
            "0          cor    112\n",
            "1      ruption     12\n",
            "2    involving     67\n",
            "3  contractors     11\n",
            "4        chief    275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AAazDp68Drc"
      },
      "source": [
        "sAll, sTox, sNT = wordScoresAll, wordScoresTox, wordScoresNT"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqdOJ6ze8Dsq",
        "outputId": "50efec05-c292-4c2a-b0cc-87bd78a8adc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sAll[sAll['Word'] == 'like'], sTox[sTox['Word'] == 'like'], sNT[sNT['Word'] == 'like']"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(     Word  Count\n",
              " 114  like   5748,      Word  Count\n",
              " 576  like   2714,      Word  Count\n",
              " 114  like   3034)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSvuwP2i8DtN"
      },
      "source": [
        "from functools import reduce\n",
        "\n",
        "dfs = [sAll, sTox, sNT]\n",
        "df_merged = reduce(lambda left,right: pd.merge(left,right,on='Word'), dfs)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S3BHI1p8DtQ",
        "outputId": "81c1476b-a6d1-429c-ad2b-f1bacb25e27a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_merged.columns = ['Word', 'Count_All', 'Count_Tox', 'Count_NT']\n",
        "df_merged.head()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Count_All</th>\n",
              "      <th>Count_Tox</th>\n",
              "      <th>Count_NT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cor</td>\n",
              "      <td>179</td>\n",
              "      <td>67</td>\n",
              "      <td>112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>involving</td>\n",
              "      <td>83</td>\n",
              "      <td>16</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>contractors</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>chief</td>\n",
              "      <td>342</td>\n",
              "      <td>67</td>\n",
              "      <td>275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>culprit</td>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Word  Count_All  Count_Tox  Count_NT\n",
              "0          cor        179         67       112\n",
              "1    involving         83         16        67\n",
              "2  contractors         13          2        11\n",
              "3        chief        342         67       275\n",
              "4      culprit         25          3        22"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rF848YDCEDY"
      },
      "source": [
        "df_merged['Tox_percent'] = df_merged.apply (lambda row: row['Count_Tox']/(row['Count_All']), axis=1)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "antrEBVUEuKD",
        "outputId": "3e9a58e0-f60d-4c4b-8b85-3f4dd30380bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "df_merged[df_merged['Word'] == 'fuck']"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Count_All</th>\n",
              "      <th>Count_Tox</th>\n",
              "      <th>Count_NT</th>\n",
              "      <th>Tox_percent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22011</th>\n",
              "      <td>fuck</td>\n",
              "      <td>1705</td>\n",
              "      <td>1664</td>\n",
              "      <td>41</td>\n",
              "      <td>0.975953</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Word  Count_All  Count_Tox  Count_NT  Tox_percent\n",
              "22011  fuck       1705       1664        41     0.975953"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0aQa0dKCVdK"
      },
      "source": [
        "MINFREQ = 3\n",
        "df_merged_minfreq = df_merged[(df_merged['Count_All'] > MINFREQ)]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ItuhWEIeO36"
      },
      "source": [
        "# highTox = df_merged_minfreq.sort_values([\"Count_All\", \"Tox_percent\"], ascending = [False, False])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x22NBQyaY-j",
        "outputId": "18bdc119-ada0-4b80-ceb4-4f11f1addd7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# highTox = df_merged_minfreq.sort_values([\"Count_NT\", \"Count_Tox\"], ascending = [True, False])\n",
        "highTox = df_merged_minfreq.sort_values(\"Tox_percent\", ascending = False)\n",
        "len(highTox)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21780"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgzB3q3LFlZT",
        "outputId": "fa46b498-0ec5-4e53-b68c-052ebc14a619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "highTox[:20]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Count_All</th>\n",
              "      <th>Count_Tox</th>\n",
              "      <th>Count_NT</th>\n",
              "      <th>Tox_percent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23170</th>\n",
              "      <td>pussy</td>\n",
              "      <td>178</td>\n",
              "      <td>177</td>\n",
              "      <td>1</td>\n",
              "      <td>0.994382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23216</th>\n",
              "      <td>whore</td>\n",
              "      <td>149</td>\n",
              "      <td>148</td>\n",
              "      <td>1</td>\n",
              "      <td>0.993289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23105</th>\n",
              "      <td>bitch</td>\n",
              "      <td>562</td>\n",
              "      <td>551</td>\n",
              "      <td>11</td>\n",
              "      <td>0.980427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22011</th>\n",
              "      <td>fuck</td>\n",
              "      <td>1705</td>\n",
              "      <td>1664</td>\n",
              "      <td>41</td>\n",
              "      <td>0.975953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23235</th>\n",
              "      <td>asshole</td>\n",
              "      <td>296</td>\n",
              "      <td>288</td>\n",
              "      <td>8</td>\n",
              "      <td>0.972973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23171</th>\n",
              "      <td>slut</td>\n",
              "      <td>135</td>\n",
              "      <td>131</td>\n",
              "      <td>4</td>\n",
              "      <td>0.970370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22682</th>\n",
              "      <td>fucking</td>\n",
              "      <td>1291</td>\n",
              "      <td>1243</td>\n",
              "      <td>48</td>\n",
              "      <td>0.962820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14839</th>\n",
              "      <td>cking</td>\n",
              "      <td>99</td>\n",
              "      <td>95</td>\n",
              "      <td>4</td>\n",
              "      <td>0.959596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23128</th>\n",
              "      <td>fucked</td>\n",
              "      <td>267</td>\n",
              "      <td>256</td>\n",
              "      <td>11</td>\n",
              "      <td>0.958801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21394</th>\n",
              "      <td>igger</td>\n",
              "      <td>69</td>\n",
              "      <td>66</td>\n",
              "      <td>3</td>\n",
              "      <td>0.956522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23137</th>\n",
              "      <td>fuckin</td>\n",
              "      <td>60</td>\n",
              "      <td>57</td>\n",
              "      <td>3</td>\n",
              "      <td>0.950000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22121</th>\n",
              "      <td>penis</td>\n",
              "      <td>1327</td>\n",
              "      <td>1260</td>\n",
              "      <td>67</td>\n",
              "      <td>0.949510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16032</th>\n",
              "      <td>anal</td>\n",
              "      <td>241</td>\n",
              "      <td>228</td>\n",
              "      <td>13</td>\n",
              "      <td>0.946058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23201</th>\n",
              "      <td>scissors</td>\n",
              "      <td>16</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>0.937500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23324</th>\n",
              "      <td>protr</td>\n",
              "      <td>15</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>0.933333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11838</th>\n",
              "      <td>nig</td>\n",
              "      <td>102</td>\n",
              "      <td>95</td>\n",
              "      <td>7</td>\n",
              "      <td>0.931373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7516</th>\n",
              "      <td>ussy</td>\n",
              "      <td>142</td>\n",
              "      <td>131</td>\n",
              "      <td>11</td>\n",
              "      <td>0.922535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5843</th>\n",
              "      <td>anus</td>\n",
              "      <td>109</td>\n",
              "      <td>100</td>\n",
              "      <td>9</td>\n",
              "      <td>0.917431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23157</th>\n",
              "      <td>webcam</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0.916667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23311</th>\n",
              "      <td>cerv</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0.909091</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Word  Count_All  Count_Tox  Count_NT  Tox_percent\n",
              "23170     pussy        178        177         1     0.994382\n",
              "23216     whore        149        148         1     0.993289\n",
              "23105     bitch        562        551        11     0.980427\n",
              "22011      fuck       1705       1664        41     0.975953\n",
              "23235   asshole        296        288         8     0.972973\n",
              "23171      slut        135        131         4     0.970370\n",
              "22682   fucking       1291       1243        48     0.962820\n",
              "14839     cking         99         95         4     0.959596\n",
              "23128    fucked        267        256        11     0.958801\n",
              "21394     igger         69         66         3     0.956522\n",
              "23137    fuckin         60         57         3     0.950000\n",
              "22121     penis       1327       1260        67     0.949510\n",
              "16032      anal        241        228        13     0.946058\n",
              "23201  scissors         16         15         1     0.937500\n",
              "23324     protr         15         14         1     0.933333\n",
              "11838       nig        102         95         7     0.931373\n",
              "7516       ussy        142        131        11     0.922535\n",
              "5843       anus        109        100         9     0.917431\n",
              "23157    webcam         12         11         1     0.916667\n",
              "23311      cerv         11         10         1     0.909091"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFN97YpUefu6"
      },
      "source": [
        "# highTox[:20]"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN92fIBG8Dtf"
      },
      "source": [
        "ht = highTox[:]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIADd6Ve8DuQ",
        "outputId": "d1096ef5-55c4-48db-9b15-3013c4813c35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "ht[ht['Word'] == 'damn']"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Count_All</th>\n",
              "      <th>Count_Tox</th>\n",
              "      <th>Count_NT</th>\n",
              "      <th>Tox_percent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17788</th>\n",
              "      <td>damn</td>\n",
              "      <td>648</td>\n",
              "      <td>406</td>\n",
              "      <td>242</td>\n",
              "      <td>0.626543</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Word  Count_All  Count_Tox  Count_NT  Tox_percent\n",
              "17788  damn        648        406       242     0.626543"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLwldnV-hjzJ"
      },
      "source": [
        "toxword = ht['Word'][:1]\n",
        "toxsents = wsentTox['pussy'][:20]\n",
        "for i, s in enumerate(toxsents):\n",
        "  if '\\t' in s:\n",
        "    print(i)\n",
        "    print(s)\n",
        "    print()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44TR_9eT8DvC"
      },
      "source": [
        "# todo: Compute PMI"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAxH9J4QpOWB"
      },
      "source": [
        "import sklearn as sl\n",
        "from sklearn.preprocessing import StandardScaler as ss\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plotVariance(y, title=\"\"):\n",
        "  x = range(len(y))\n",
        "  plt.plot(x, y)\n",
        "  plt.title(title)\n",
        "  plt.show()\n",
        "  plt.savefig(title)\n",
        "\n",
        "\n",
        "# Computes PCs of difference vector\n",
        "def getPrincipalComponents(D, num_comp=None):\n",
        "  pca = PCA(n_components=num_comp, svd_solver=\"auto\")\n",
        "  X = D[0].cpu().detach().numpy()\n",
        "  pca.fit(X)\n",
        "  exp_var = pca.explained_variance_ratio_\n",
        "  return torch.Tensor(np.array(pca.components_)), exp_var"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROT6ZTYJtCsE"
      },
      "source": [
        "def projection(a, b):\n",
        "  inner = torch.mm(a, b.T)\n",
        "  res = a - torch.mm(inner, b)\n",
        "  return res"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjiYHAoV37Za"
      },
      "source": [
        "**Debiasing Roberta**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV5WCtls5Tj7",
        "outputId": "6510f540-b928-4e94-9cb9-91cc1445abb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "num_words = 10\n",
        "num_sents = 10\n",
        "print(tokenizer.pad_token)\n",
        "print(roberta_model.config.vocab_size)\n",
        "print(roberta_model.embeddings)\n",
        "print(roberta_model.encoder.layer[0])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<pad>\n",
            "50265\n",
            "RobertaEmbeddings(\n",
            "  (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
            "  (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "  (token_type_embeddings): Embedding(1, 768)\n",
            "  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "RobertaLayer(\n",
            "  (attention): RobertaAttention(\n",
            "    (self): RobertaSelfAttention(\n",
            "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (output): RobertaSelfOutput(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (intermediate): RobertaIntermediate(\n",
            "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "  )\n",
            "  (output): RobertaOutput(\n",
            "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_YKG-1EBSBL"
      },
      "source": [
        "class LayerRoberta(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(LayerRoberta, self).__init__()\n",
        "    self.emb = roberta_model.embeddings\n",
        "    self.blocks = roberta_model.encoder.layer\n",
        "    self.bert = bert_model\n",
        "\n",
        "\n",
        "  def forward(self, layer_num, inp, attn_masks):\n",
        "    \n",
        "    if layer_num == 0:\n",
        "      input_shape = inp.size()\n",
        "      inp = inp.view(-1, input_shape[-1])\n",
        "      batch_size = inp.shape[0]\n",
        "\n",
        "      device = inp.device\n",
        "      \n",
        "      return self.emb(inp)\n",
        "\n",
        "    else:\n",
        "      block = self.blocks[layer_num-1]\n",
        "      device = inp.device\n",
        "      input_shape = inp.size()\n",
        "      ext_attn_mask: torch.Tensor = self.bert.get_extended_attention_mask(attn_masks, input_shape, device)\n",
        "      return block(inp, ext_attn_mask)[0]\n",
        "      \n",
        "    # hidden_states = self.ln_f(hidden_states)\n",
        "    # output_shape = input_shape + (hidden_states.size(-1),)\n",
        "    # hidden_states = hidden_states.view(*output_shape)\n",
        "\n",
        "\n",
        "\n",
        "layerRoberta = LayerRoberta()\n",
        "layerRoberta = layerRoberta.cuda()\n",
        "# device = torch.device('cpu')\n",
        "# layerGpt2 = layerGpt2.to(device)\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXAZDrONOBPI"
      },
      "source": [
        "# this algorithm takes in toxic sentence and corresponsing nontoxic sentence\n",
        "# and returns layer wise PC set {P_0, ..., P_12}\n",
        "def run_roberta_algorithm(S_t, S_nt, model, debias=True):\n",
        "    # inputs are encoded sentences\n",
        "    W_t, W_nt = S_t, S_nt\n",
        "\n",
        "    inp_ids_t, attn_masks_t = W_t['input_ids'], W_t['attention_mask']\n",
        "    inp_ids_nt, attn_masks_nt = W_nt['input_ids'], W_nt['attention_mask']\n",
        "\n",
        "    u, v, D, PCs, ev = [None] * 13, [None] * 13, [None] * 13, [None] * 13, [None] * 13\n",
        "    \n",
        "    inp_t = inp_ids_t.cuda()\n",
        "    atn_t = attn_masks_t.cuda()\n",
        "    # inp_t = inp_ids_t\n",
        "    # atn_t = attn_masks_t\n",
        "    \n",
        "    # print('inp_t', inp_t.shape, 'atn_t', atn_t.shape)\n",
        "    u[0] = model(0, inp_t, atn_t)\n",
        "    # print('u[0]', u[0].shape)\n",
        "\n",
        "    inp_nt = inp_ids_nt.cuda()\n",
        "    atn_nt = attn_masks_nt.cuda()\n",
        "    # inp_nt = inp_ids_nt\n",
        "    # atn_nt = attn_masks_nt\n",
        "    \n",
        "    v[0] = model(0, inp_nt, atn_nt)\n",
        "    \n",
        "    D[0] = u[0] - v[0]  # todo: check dim, torch. ?\n",
        "    # print('D[0]', D[0].shape)\n",
        "    PCs[0], ev[0] = getPrincipalComponents(D[0])\n",
        "    \n",
        "    PCs[0] = PCs[0].cuda()\n",
        "    # print('PC[0]', PCs[0].shape, 'ev[0]', ev[0].shape)\n",
        "\n",
        "    for j in range(1, 13):\n",
        "        # print(\"BERT Layer j =\", j)\n",
        "        if debias:\n",
        "          uproj = projection(u[j - 1][0], PCs[j - 1])\n",
        "          vproj = projection(v[j - 1][0], PCs[j - 1])\n",
        "        else:\n",
        "          uproj = u[j-1][0]\n",
        "          vproj = v[j-1][0]\n",
        "\n",
        "        uproj = uproj.unsqueeze(dim=0).cuda()\n",
        "        vproj = vproj.unsqueeze(dim=0).cuda()\n",
        "        u[j] = model(j, uproj, atn_t)\n",
        "        v[j] = model(j, vproj, atn_nt)\n",
        "        \n",
        "        D[j] = u[j] - v[j]  # todo: check dim, torch. ?\n",
        "        PCs[j], ev[j] = getPrincipalComponents(D[j])\n",
        "        PCs[j] = PCs[j].cuda()\n",
        "\n",
        "        # print('PCs[j]', PCs[j].shape)\n",
        "\n",
        "    return PCs, ev\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av8eN2ITOO4U",
        "outputId": "67f3ebe7-8e1c-4f00-97b3-7458b1edbc97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "toxic_words = ht['Word'][:num_words]\n",
        "ev = [0]*13\n",
        "count = 0\n",
        "# find toxic words and their sentences\n",
        "for word in toxic_words:\n",
        "  \n",
        "  sents = wsentTox[word][:num_sents]\n",
        "  print('word', word, 'num_sent', len(sents))\n",
        "  sflag = False\n",
        "  for sent in sents:\n",
        "    if count % 10 == 0: print(count)\n",
        "    # encoded_text = tokenizer(sent)\n",
        "    encoded_text = tokenizer.encode_plus(\n",
        "        sent, add_special_tokens=True, truncation=True,\n",
        "        max_length=256, padding='max_length',\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt')\n",
        "    tox, attn_masks = encoded_text['input_ids'], encoded_text['attention_mask']\n",
        "    ntox = tox.clone()\n",
        "    # print(tox)\n",
        "    tokens = list([tokenizer.convert_ids_to_tokens(i) for i in ntox][0])\n",
        "    tokens = [tok[1:] if tok[0] == 'Ä ' else tok for tok in tokens]\n",
        "    try:\n",
        "      idx = tokens.index(word)\n",
        "    except:\n",
        "      print('PROBLEM!')\n",
        "      print(sent)\n",
        "      continue\n",
        "      # sflag = True\n",
        "      # break\n",
        "\n",
        "    ntox[0][idx] = 0\n",
        "\n",
        "    encoded_T = {\n",
        "        \"input_ids\": tox,\n",
        "        \"attention_mask\": attn_masks\n",
        "    }\n",
        "    encoded_NT = {\n",
        "        \"input_ids\": ntox,\n",
        "        \"attention_mask\": attn_masks\n",
        "    }\n",
        "    principal_components, exp_variance = run_roberta_algorithm(encoded_T, encoded_NT, layerRoberta, debias=True)\n",
        "\n",
        "    for i in range(13):\n",
        "      ev[i] += exp_variance[i]\n",
        "    count += 1\n",
        "\n",
        "  if sflag:\n",
        "    break\n",
        "print(count)\n",
        "# print('ev[0]', ev[0])\n",
        "# todo: Use BERTForSentenceClassification then check the classifier hidden output\n",
        "\n",
        "# a = num_sent x 768\n",
        "# b = 2 x 768 PCs\n",
        "# inner = a . bT -> num_sent x 2\n",
        "# inner . b -> num_sent x 768\n",
        "\n",
        "\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word pussy num_sent 10\n",
            "0\n",
            "tensor([[    0,   627,   299,   158, 14016,   607,  7758,  4060, 20616,    32,\n",
            "         17072, 34781,     6, 17072,  1898,     6, 14844,     6,  6814,     6,\n",
            "         17072,  1898,  4111,  5046,     6,  2231, 14682,  2553,     6, 17072,\n",
            "          1898, 37628,     6,  4091,   438, 19644,     6, 42167,     6,     8,\n",
            "         17072,  1898,  4111,     4,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,  1843,  4406,    12,   605, 16430, 16448, 33318,  3379,    69,\n",
            "            22,   605,   594, 42167,   113,     8, 21969, 43194,  1363,  4501,\n",
            "             6,  2490, 12445,   602,    10,   741,  1222,  6576,   102,  1548,\n",
            "            11, 25578,  2802,  3009,     5, 37367, 24493,     9, 28410,  7085,\n",
            "           493,    18, 15351,  1104,    12, 25868,    12, 31336,  6605, 13591,\n",
            "           435,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0, 30453,   337,  4401,  7873,  5328,  6907,    44,    48,   642,\n",
            "         28102,    17,    46, 15146,     6,     8,  2584, 22058,    19, 20114,\n",
            "           101,    35,    44,    48,  9226, 42167, 21482,   124,    17,    46,\n",
            "            71,     5, 17837,     9,    10,  4013,  7898,    11,    61, 20125,\n",
            "          1834,     9,   390,    11,    10,  4410,   242, 19266,   169,  6246,\n",
            "          5859, 10618,     4,     2,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   113,  1594,   939,  4951,   910,  2001, 11089,  9958,    41,\n",
            "           267,   366,     6,   114,    37,   399,    75, 42167,    66,     9,\n",
            "            14,    94,    65,     8,   969,    62,     6,     5,  2347,   939,\n",
            "         16212,   295,   877,    19,    11,     5,    78,   799,   728,     9,\n",
            "            14,   646, 16695,   742,    74,   348, 12546,  1017,   910,  2001,\n",
            "         11089,  9958,    41,   267,   366, 13116,     4,     2,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   463,    98,     6,     7,  1877,     5,    44,    48,  9426,\n",
            "         10917, 42167,    17,    46,  8986,     9,     5,   499,     6,    52,\n",
            "         23222,   578,   179,  9327,  4617,   578,  9178,    42,   237,    76,\n",
            "          1030,  2168,   227,    80,   320,   588,   790, 17226,   376,     7,\n",
            "            28,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0, 39388,     7,   249,   690,   703,    71,     5,  2237,     6,\n",
            "          1349,  8750,   179, 19835,   352,  1451,    39,  6096,     6,   172,\n",
            "           342,    41,  4709,    12,   996,     7,    39,   471,     8,   326,\n",
            "         19264,    69,    13,    45, 13294,    37,    17,    27,   417,  3549,\n",
            "          1003,     6,   584,     6,    44,    48,  5016,    47,   206,   939,\n",
            "            17,    27,   119,    10, 42167,   116,    17,    46,     2,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,  4651, 11458,  2318,     8,   320, 37958,  1939,  1984,  1855,\n",
            "          4663, 29224,   324,    15,   326, 47478,   662, 20461,   196,    11,\n",
            "            59,     5,  4013,   569,     9,   218,  5618, 20125,   442, 28792,\n",
            "          1450,    59, 16004,   390,    30,     5, 42167,     4,     2,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   627, 20125,  9906,    18,  3231,    12, 31628,   963,    10,\n",
            "           569,  6590,  2018,   394,  6168,  2583,  5783,    22,  8643,    29,\n",
            "             8, 42167,   350,   113,    14,    21, 18296,    15,   592,   433,\n",
            "           552,    19,   484,  3950,    50, 12030,  1449,     4,     2,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   605, 30312,     8, 25668,  8825,  2368, 41507,    10, 38463,\n",
            "          1794, 17802,     5,  1196,   474,    13,     5,   511,    76,     8,\n",
            "          2081, 14633, 42167,    12,  6677,  1722,  9836,    13, 29521,  1334,\n",
            "         12644,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   113,   700,    18,   626,    60,  3167,  2971,     9,  1669,\n",
            "            23,     5,  2003,  1236,  5113,  1481,  6506,   254,    26,    11,\n",
            "            39,  3172,  1929,  4166,     6,    95,   137,     5,  1540,  3447,\n",
            "           365,    12,   288,    14,    70,    14, 42167, 42647,    62, 14193,\n",
            "           108,  3255,     9,  3433, 10267, 32715, 33012,   108, 11466,   638,\n",
            "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "word whore num_sent 10\n",
            "10\n",
            "tensor([[    0,  4297,    77,    65,  1519,    10,   320,  1177,  2839, 25238,\n",
            "            10,   449,    12, 20521, 45590,    15,    41, 23732,  3188,   311,\n",
            "             6,    65,    34,  1622,  1613,   350,   444,     6, 21958,  9772,\n",
            "             6,     8,    24,    40,    45,    28, 22639,     4,     2,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   462,  8772,   475,  1766,   885,  2723,   607, 27121, 11993,\n",
            "             6,    10,  5918, 16893,     8,  1601,    12,  9408,     6,  3374,\n",
            "            44,    48,   506, 35367,  2241,  3807,  5410,    17,    46,     6,\n",
            "            10,    44,    48, 30160,  6618, 45590,    17,    46,    11,    10,\n",
            "         11216,  5278,  3343,     4,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   261,    92,    76,    17,    27,    29, 15330,     6,   939,\n",
            "         43867,  9997,  4855,   127,  2846, 45590,     6,  9079,     8,   172,\n",
            "           703,    69,    35,     2,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   179,    39,  1273,   445,     6,   251,  4487,  4435, 37572,\n",
            "            13,   519,  4997,     7,    10,  2182,   752,  6114,  4988,     8,\n",
            "           320,  1177,  2839, 25238,    25,    10,    22,   330,  2014, 45590,\n",
            "            72,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0, 40100,  4731,    10,  5217,  3627,    40,    33,    42,  2157,\n",
            "           187,    37,    17,    27,   890,    33,  7741,     9,  3549, 34554,\n",
            "            50,    23,   513,    28,   326,  4628,    15,  3549, 34554,     6,\n",
            "          7425,   118,   630,    17,    27,    90,    33,     5,    86,  3486,\n",
            "             5,  1460,     7, 45590,    15,   475, 11791,     4,     2,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,  4651, 11458,  3763,   181,  5906,   385,  4291,   462,  1580,\n",
            "            34,   351,    10,   275,  3117,  2701,    11,    10,  4149,  2841,\n",
            "          4783,    13,    39,   774,    25,     5,   885, 45046,   338,  7361,\n",
            "             6, 45590,    12,   611,  7913,    22, 11850,   113, 49178,  1499,\n",
            "           784,  2279,  4742,    11,  1368,  3983,    18,    92,   651,     6,\n",
            "            22,  2670,     9,  3553, 30133,    72,     2,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,  4057,    17,    27,    29,  3795,  4533, 28692,    16,   471,\n",
            "             9,     5,  1139, 45590,  3138,     6,   192,     6,     8, 36631,\n",
            "          3677,     9,    69,   920, 15433,   159,    19,   103,  4607,    54,\n",
            "           429,    45,    28,   441,     7,   694,    13,    69,  1354,   182,\n",
            "           157,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,  4862,   179, 19348,  2084,   493,     6,    36,   627, 21725,\n",
            "         45590,    43,  8268,    39,   301,   409,    71,   129,   389,  2397,\n",
            "             6,  1618,  9881, 27945,   268,    10,  4147,  1988,    25,    84,\n",
            "          6132,  1145,    19,     5, 17244,     9,    39,  1068,     6,  3064,\n",
            "             7,    41,  7587,  4235,   352,   744,    71,   145,  8401, 10074,\n",
            "           160,    14,   410,  2972,  4822,   631,    11,  3238,   231,     4,\n",
            "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0, 10669,    10,   181, 11850,    17,    27,    29,  1800, 10195,\n",
            "         27345,     6,    37, 16418,    39,    92, 45590,  2500,     5,  2827,\n",
            "             7,  4073,   418,    13,   123,     4,     2,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   281,     5,   206,  6013,  2002,    11,    10,   340,   800,\n",
            "             6,    24, 11573,   196,     5,  7409,   668,   298,  3876,    13,\n",
            "         10960,     9,     5,  1617, 44046,     8, 45590,     6,     8,   172,\n",
            "           341,    10, 14101,  1632,    12, 19527,  5774,   586,   373,  5448,\n",
            "          4429,     7,  3094,    61, 10960,    58, 11248,    73,  1397,  4352,\n",
            "          2963,     8,    61,    58,   888, 14202,     4,     2,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "word bitch num_sent 10\n",
            "20\n",
            "tensor([[    0,    17,    48, 34727, 32594, 35824,    17,    46,     8, 18746,\n",
            "             9,    44,    48,   438,  5973,    17,    46,    58,   566,     5,\n",
            "         25763,  1371,  1450,   314, 11352,    24,    15,    49, 10660,  1842,\n",
            "           578,  7443,    29,  3244,  2933,   352,     9,  1370,    12, 35151,\n",
            "          9774,     7,    69,   284,     4,     2,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   118,    56,    65,  2943,  1441, 32594,    66,     9,  8413,\n",
            "            59,    45,   562,   143, 21482,   149,   326,  7026,  3486, 15983,\n",
            "         16312,  1588,   417,     4,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,  7443,    29, 32594,    59,     5, 40908,  1029,    12,  1517,\n",
            "         12111, 15358,    14,  1382,    23,  1709,     4,     2,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   405,   938,    17,    27,    90,    14,   251,   536,    77,\n",
            "           201,  2971,     9,   194, 29227,  1506, 13301,  6082,  5915,  9473,\n",
            "          2071,    25,    44,    48, 16918, 25753,  5954,    17,    46,     8,\n",
            "           394,  4066,  1120,   295, 28427,  1602,  9473,   811,  2654,  1269,\n",
            "          9473,  3578,   821,   463,  3592,    25,    44,    48,  6025, 32594,\n",
            "            17,    46,     4,     2,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0, 39114,  7223,     6,  3741,  2088,  2084,   605,   354,    34,\n",
            "          1167,    10,   455,  9664,    71,    37,   174,    10,  2943,  2437,\n",
            "           919,     7,    44,    48,  6460,    15,   110, 15145, 32594,    17,\n",
            "            46,   148,    10,  2798,  3221,     4,     2,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   700,   399,    75, 16082,    66,    13,    10,  4603,     6,\n",
            "          5998,     7,  3008,    39,   633,     6,    50, 32594,    59,    39,\n",
            "           447,  1274,     4,     2,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   438, 15688,  2850,  8855,     5,  6994,  3021,  2195,    11,\n",
            "          9473,  8878,     7,   465,     5,    65, 29412,  3200,     7,   283,\n",
            "            15,     8, 32594,    59, 20125,     4,     2,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0, 10443,   218,  5618, 20125,  5343,     7,    22, 30191,    15,\n",
            "           349,     9,   106,   101,    10, 32594,   113,  5579,  3335,     6,\n",
            "          2029,    39,   380,  1901,     4,   540,  2182,   453,     9, 12442,\n",
            "          3568,  1104,     7,  3712,     5,   390,    18, 15544, 17952,  2079,\n",
            "             8,   323,   390,    18,   659,    25,  1717,     4,    29,     4,\n",
            "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,  5016, 17942,  1207,    11,     5,  3072,    33,    10,   235,\n",
            "             7, 32594,    59,  1475,    12,  9830, 13453,   116,     2,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   405,    18,    45,  1341,    25, 33200,    25,  6177,     7,\n",
            "           146,    47,    39, 32594,     6,    53,  1021, 46283,   748,   338,\n",
            "           740,   560, 41906,   512,   119,  2990,   161,   380,   383,    32,\n",
            "            11,  1400,    13,    82,    54,   860,     5,  1021, 46283, 23708,\n",
            "           748,   338, 20084,    13,     5,    78,    86,     4,     2,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "word fuck num_sent 10\n",
            "30\n",
            "tensor([[    0,   506, 30672,     6,    71,    80,   107,     9,   803,     8,\n",
            "           615,  6769,  5634,     7,  3300,    10,  3135,    12,  8596,   266,\n",
            "            15,     5,   803,    18, 26536,    12,  4489,     6,     5,   295,\n",
            "          3245,   102,   851,   475, 40879,    63,   781,  3120,     9,  1857,\n",
            "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   627,   740,   493,    33,   460,    57, 30580,    11,  2609,\n",
            "          5808,  1319,     7,    28,   720,    12,  8056, 26536, 12744,     8,\n",
            "            24,    18,  2579,     7,   192,    14,    49,  1989,  1518,     9,\n",
            "           301,    12,   463,    12, 24483, 17605, 19650,  5313,    34,  5116,\n",
            "         32423,     7,     5,  5381,    12,  1580,     4,     2,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,    17,    48,  5593, 13871,  7901,   189,   146,   103, 44736,\n",
            "          1129,   994,    36, 34378,   547,    62,    25,    65,     9,     5,\n",
            "           144, 32101,  7721,     9,     5,  2888, 26536,   605,   625,  6680,\n",
            "            23,   173,    43,   206,  2330,    59, 29400,   154, 31617,  6514,\n",
            "         20175,    70,    81, 44736,  3424,     6,    17,    46,    47,    90,\n",
            "         17968,  1236,   757,    47,   282,  4245,   875,     4,     2,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,  3340, 45314,     5, 12704,    13,    42,  4613,   592,  4695,\n",
            "            16,    44,    48,   560,   120,   124,    23, 26536, 22505,    17,\n",
            "            46,    36,   118,     4,   242,     4,    13,   390,     7,  3951,\n",
            "           604,     5,   169,    51,    17,    27,   548,  4100,    57,  3032,\n",
            "            77,  7031,  1545,   552,    13,    10,   150,    30,    10,  2173,\n",
            "           322,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0, 21290, 18254,     7,   310,    44,    48, 44412,    62,   103,\n",
            "          7034,   281,     6,    17,    46,    44,    48, 43776,   160,     6,\n",
            "            17,    46,     8,    44,    48, 43750,   397,    17,    46,   203,\n",
            "             7,     5,  8817, 13213,     4,     2,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   705,   401,    35,  3068,     5, 14489,    23, 40373,    90,\n",
            "          5858,  4384,     6,   733,  2834,     6, 26536,     5,  5448,    23,\n",
            "         40373,    90,  5858,  4384,     6,   195,  2834,     2,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,  1097,  1506,  1196,   314, 22602,  3731,    23,     5,  1082,\n",
            "             9, 20437,   298,   459,   462,    18,   744,     6,   217,    41,\n",
            "          2274,     9,    10,  1692,  8411,    19,     5,  1617,    22, 44412,\n",
            "          2955,  4891,   113,  2850, 35352,   420,    24,     6,   634,     5,\n",
            "          4709,   873,   636,   766,    13,     5,    16,  5112,   636,   194,\n",
            "           333,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   627,   800,     6,  7919,    22,  7968,   102,   897, 34161,\n",
            "           763,   113,    36, 44412,     5,  1424,  8691,    43,    16,     5,\n",
            "            78,    86,   784, 24853,  8584,    18, 23290,     7,   800,  1081,\n",
            "           335,     9,   168,  3525,     6,  1195,    87,    95, 24127,    49,\n",
            "          7656,    36,  7048,    35,   740,   493,     6,   201, 22437,   322,\n",
            "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   462, 24639, 24279,  1236,   922,   811,  7142,    21, 27554,\n",
            "          1527,   101, 26536,     7,   146,    39, 20812, 21068,    12, 12528,\n",
            "         14678,   213,  3845,    77,    39,  1144,     8, 19147,  1348,  4532,\n",
            "          2148,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0, 10321,  3178,     6,    10, 26139,  1342, 20125,  9906,     6,\n",
            "           373,   453,     9,     5,  1423, 14960, 19936,   435,    44,    48,\n",
            "           438, 19667,    17,    46,     8,   174,   106,     7,    44,    48,\n",
            "         44412,   160,    17,    46,   656,    14,   183,    11,    10, 10819,\n",
            "         10660,  3221,    59,  8222,    71,     5,   729,     4,     2,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "word asshole num_sent 10\n",
            "40\n",
            "tensor([[    0,  8585,    40, 14217,    28,    82,    54,  1166,    42,    14,\n",
            "           206,     9,   162,    25,    41, 43870,    13,     5,  4312,   939,\n",
            "            40,  5486,   874,     6,    53,   939,   206,    24,    17,    27,\n",
            "            29,   966,  8668,   209,  2956,  6992,     4,     2,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,    17,    48,   627, 43870,  4504,    66,     9,    10,   933,\n",
            "          1472,    14,    37,    16,   780,     6,    14,  2340,  1492,     9,\n",
            "          2883,   109,    45,  3253,     7,   123,     6,    17,    46,  1236,\n",
            "         12336,  5789,    11,    39,  1125,  3149,     4,     2,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   179,     5,  9915,  1536,     9, 32756,  8196, 14186,     6,\n",
            "            54,    64,  4309,     5, 15835, 43870,  1076, 37298,  1825,     9,\n",
            "            42, 24032,    64,  5029, 12867,     6,  2638,    30,    80, 11962,\n",
            "          1972,    23,   683,     6,    54,   385, 19605,     5,  4198,     9,\n",
            "          8728, 41128,    19,    10,   122,    12, 41755,  2069,     7,    44,\n",
            "            48, 29715,     5,  4133,    17,    46,     4,     2,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   118,   101,    14,   939,    64,    28,    10,   746,  1475,\n",
            "            12, 47899, 43870,    50,    28,  2579,     8, 23303,    36,   118,\n",
            "            21,  2579,     6,    42,    16,    10,  1759,    12, 47899,  6730,\n",
            "           322,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,  3662, 11691,  2865,     8,    97,  4066, 43870, 28329,    64,\n",
            "          4960,     7,    66,  4182,  1397,   201,   158,     7,   112,    50,\n",
            "           190,   291,     7,   112,    11,   358,   194,    14,    34,     5,\n",
            "          5250,     8,    24,   351,    17,    27,    90,   342,    10, 14368,\n",
            "            11,    49, 16927,     4,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,  3866,  5229,  1656,   254,    21,    41,  7540, 31006,   868,\n",
            "         43870,    77,    78,  2736,     6,     8,   362, 26714,   821,  7445,\n",
            "            11, 31003,    39,  6845,   537, 14320,    19,    14,     9,    39,\n",
            "          3174,  8523,   578,  1873, 36001,   213,   705,     4,     2,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,  7443,    29,  5848,    24,    17,    27,    29,    95,    10,\n",
            "           948,     9,   951,   145,    41, 43870,  1954,     4,    45,    41,\n",
            "         43870,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,  7443,    29,  5848,    24,    17,    27,    29,    95,    10,\n",
            "           948,     9,   951,   145,    41, 43870,  1954,     4,    45,    41,\n",
            "         43870,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   700,    17,    27,    29,    10,  5918,  2701,    54,    64,\n",
            "           310,   258,     5,   784, 30289, 24587,     8,     5, 30967, 43870,\n",
            "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   118,    17,    27,   119,  1153,    95,   145,    10, 22414,\n",
            "         43870,     6,    98,    14,    17,    27,    29,  5063,   259,     6,\n",
            "          3486,    89,     4,     2,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "word slut num_sent 10\n",
            "50\n",
            "tensor([[    0, 25616,    62,     6,    10,  1345,     9,     5,   320,  2982,\n",
            "          2596,  9231,  4045, 12690, 34863,    88, 29768, 40058, 44046,     6,\n",
            "           475,  9422,   740, 44224,     6,  4009,    11,    10, 15686, 13301,\n",
            "            19,    10,  2422,  1421,    14,    34,    41, 33209, 10523, 17213,\n",
            "            11, 18011,     4,     2,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   627,  3545,    21,    10,  1263,     7,  1613,  1816,  3390,\n",
            "          2841,  5846,   910,  2186,   267, 11779,     6,    54,  7194, 15352,\n",
            "          8295, 20125,   656,    42,   186,    71,    10,    92,  1423,  9657,\n",
            "           498,  4439,  1027, 44046,    12,  1193,  9708,  1450,     4,     2,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,  4339,   282, 23219,  1482,  4803,  8447, 26226,    16,   684,\n",
            "            13,    39,  8944,   428, 12589,  1912,    15, 16441,  1253,    53,\n",
            "            24,  1326,   101,    37,   189,    33,  7344,     5,   516,    15,\n",
            "            39,   311,  2350,    30, 27963,   784, 34541, 21691, 27092,    10,\n",
            "            44,    48,  4070,  5897, 44046,     4,    17,    46,     2,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   113,   415,   127,   334,    52,  1798,   130,  1617,     6,\n",
            "         44046,     6, 43577,     8,  3369,  1073,     6,   358,   183,     4,\n",
            "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0, 18891,     7,     5,  1683,     9,    14, 13816,  4393,    21,\n",
            "            10, 44046,     8,     7,   120,    69,     7,   989,     5,   449,\n",
            "          2401,   261,    12,   119,   927,   368,  1352,   334,     6,   556,\n",
            "            42,     7,   961,    47,   216,    60,  4095,  1855,  4663,  2342,\n",
            "           260, 25736,   174,     5,  1992,     4,     2,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   627,  1569,    17,    27,    29, 16068,   225,    36,  1264,\n",
            "            19,    10,   356,     9,    10,  3757, 44046,    43,     8,    10,\n",
            "           611, 22244,    36,  3809,   625,   181,  2582,    43,    58,  1195,\n",
            "         11962,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   118,  1798,     5,  1385,    44,    48,   642,  5858, 44046,\n",
            "            17,    46,  5861,  5629,   198,    15,  7409,     4,     2,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0, 12196,   269,  1102,    21, 44046,    12,  1193,  9708,   646,\n",
            "          1116,   263, 11369,   102, 48677,    17,    46,    79,   355,     4,\n",
            "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0, 39388,     7,    63,   998,     6, 44046, 10097,    21,  1412,\n",
            "            30,   390,    54,    44,    48,  1322,  7428,     9,   145, 32881,\n",
            "            30, 44046,    12,  1193,  9708,   131,     9,   145, 16247,    30,\n",
            "           646, 25017,   742, 17969,     8,  2157, 16031,    25,    10,   898,\n",
            "             4,    17,    46,     2,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   113,   627,  1972,    56,    80,  5717,    35,    51,   115,\n",
            "          1656,   198,    25, 17059,  1972,     8,  1807, 19072,     8, 16328,\n",
            "             7,     5,  2786,     6,    50,    51,   115,  3008,   402,   373,\n",
            "            10, 44046,  3836,   147,    51, 23598,    11,    49, 20745,    60,\n",
            "            10,  2182,  1564,  1294,    26,     4,     2,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "word fucking num_sent 10\n",
            "60\n",
            "tensor([[    0,   462,   119,   506,  3853,   939,    17,    27,   119,    98,\n",
            "          7428,     9,  1104,  6737,   634,    84,  2400,     8,  8795,    13,\n",
            "            49,   308, 23523,  1963,    14,    17,    27,    29,    99,   269,\n",
            "         10469,   162,    59,     5,  8257,    25,    10,  1086,     4,    51,\n",
            "           362,    84,  3734,     8,    84,  2400,     8,  1381,     7,  1050,\n",
            "          2072,    69, 28051,   116,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   281,   228,  4505,     6,  3553,   271,  1910,    21, 25275,\n",
            "           154, 16785,   179,    18,  5296,     6, 37314,     8,  6797,   493,\n",
            "            58, 23523,    11,     5, 16198,     6,  2628, 13861,    21, 30309,\n",
            "           154,   198, 17802,    79,    21,    10,   313,     6,   122,   118,\n",
            "            21,  5336,   739, 10889,    23,   295,   895,    18,   471,     6,\n",
            "             8,  1690,  9791,    21,   608,    97,  1713,     4,     2,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,    17,    48, 14746,     5, 12133,  2029,    10, 23523, 12029,\n",
            "             7, 19742,    17,    27,    29,   843,   212,  4038,    76,     6,\n",
            "            47,   216,   402,    34,  1613,  3640,  1593,     6,    17,    46,\n",
            "          9240, 20287,  4529,     4,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   463,   150,  5552,   101,  1076, 18234,  1696,     8,  4533,\n",
            "          6747,  3069,  4712,    33, 36865,     5,  1808,     9,  7843, 11626,\n",
            "            12,   179,    10,   819,     6,  5907,    34,  1341,  9184, 16051,\n",
            "            18,  1460,     7,   146,   201,  5170,   114,    37,    18, 23523,\n",
            "            19,   201,     4,     2,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0, 15964,   179,    35,   117,   939,   218,    17,    27,    90,\n",
            "           206,    98,    44,   711, 27037,    52,    17,    27,   890, 23523,\n",
            "         21183, 15285,    24,     4,    89,    17,    27,    29,   117,  1465,\n",
            "             4,   939,   657, 16207,   261,     6,    53,   117,  1465,     4,\n",
            "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   627,  1971,  1395,  2067,     7,   671,     7,     5,   982,\n",
            "            35,    22,  1694,   214,    98, 23523,  2283,    59,  3357,     7,\n",
            "          1926, 38187,   102,    19,    10,   455,  8707,   311,     6,     8,\n",
            "           519,     5,  9227,  2342,  5992,   424,     8, 10622,   424,    25,\n",
            "           780,  3958,   269,  2607,   342,    42,    81,     5,   299,   328,\n",
            "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   463,   648,     6,    89,    16,     5,  2737,     9,  5251,\n",
            "         46295,     6,    68,  1549,     6,   151,    11,     5,  1275,    71,\n",
            "            63,    78,    76, 23523,    62,     5,  4607,    11,    10, 12644,\n",
            "          1400,   265,    23,   326, 19911,  4773,     4,     2,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,    17,    48, 14746,    52,  8102,     8,    51,    58,  6062,\n",
            "            13,    10,  5010,   939, 21619,    51,    17,    27,   417,    95,\n",
            "           517,   106,     7,     5,   299,     9,     5,  1087,   142,    51,\n",
            "         23523,  6565,     7,    28,    89,     6,    17,    46, 11491, 11639,\n",
            "           355,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,  9178,  2555,    74,    14,    28,    13,  2003,  2990,  6168,\n",
            "          2583,     7,   825,  1255,  4276,    15,   361,    73,  1225,     6,\n",
            "           129,   688,    71,    37,   399,    75,   213, 23523, 18544,    81,\n",
            "            10,  1850, 11721, 10839,   745,   484,  5491,   409,   116,     2,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,  4297, 13182,   219,    17,    27,    29,   184,     6,    37,\n",
            "            64,   192, 11051,  1638,  7436,     6,     8,    37, 17216,     8,\n",
            "         16578,    39,  2473,    31,     5,  3778,     8,  2653,  5373,    19,\n",
            "         11098,     6,     8,    42,    34,     7,    28,     5,  2635,   990,\n",
            "         23523,  4293,    11,     5,   232,     6,    53,    23,   513,    37,\n",
            "            34,    10,   205,  1217,   150,    37,  8524,     9, 43635, 11465,\n",
            "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "word cking num_sent 10\n",
            "70\n",
            "tensor([[    0,  1943,  2614,    93,    44,    48,  6025,    16,   856,  3226,\n",
            "         32370, 13074,     6,    17,    46,    26, 21576,  2342, 27559,     6,\n",
            "          2357,     6,    25,    52,  4005,    11,    10, 24037, 16381,    11,\n",
            "         14719,  2614,    17,    27,    29,   475, 13537,  1418,     4,     2,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   102,  1860,    61,  1171,    28,  3628,  1033,     6, 42031,\n",
            "          2485,     6,     8,     5, 14471,     9, 14767,     6,     8,    24,\n",
            "            70, 38618,    31,    49,   856,  3226, 32370,  1040,     6,     5,\n",
            "           129,  1040,    51,   655,  1166,   955,     2,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0, 22098,   162,  1178, 12657,   394, 32438,  8530, 23602,   174,\n",
            "          1865,    42,   186,    37,    74,    45,   582,    13,   218,  5618,\n",
            "         20125,    17,    27,    29,    44,    48,   506,  3226, 32370,  2204,\n",
            "             4,    17,    46,     2,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   620,  2753,  2013,  2002,    14,    95,   142,   402,    16,\n",
            "            44,    48, 16625,   856,  3226, 32370,  2979,    17,    46,   630,\n",
            "            17,    27,    90,  1266,    24,    17,    27,    29,    95,    25,\n",
            "          8218,    25,  4776,  6441,   754,     4,     2,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,    17,    48, 39088,     6,   939,   524,    95,   626,   145,\n",
            "         25673,  4075,    59,   408,     8,    49,  1078,    30, 31420, 12589,\n",
            "            12,   506,  3226, 32370, 19929,     6, 15843,     6,  1886, 17552,\n",
            "             4,    17,    46,    37,  1143,     4,     2,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,    17,    48,  1264,  2173,     6,    10,  1441,     9,  4318,\n",
            "            26,     6,    44,   711,   698,     6,    14,    17,    27,    29,\n",
            "          6925,   868,   131,   365,     6,    14,    17,    27,    29,  6925,\n",
            "           868,   131,   379,    16,   856,  3226, 32370,  9227,     6,    17,\n",
            "            27,    17,    46, 41906,  1478,    26,    42,   186,    15,    10,\n",
            "          1717, 25484, 21891,   433,  1019,   486,     4,     2,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   179,    41,  1194,    19,     5,  9202,     6, 12899, 11959,\n",
            "            26,     5,   604,    58,  7594,    59,   218,  5618, 20125,     8,\n",
            "            14,    25,    37,   314,     7,   213,     7,     5, 29278,     6,\n",
            "         16531,  7249,    39,  3124,     8,   373,   123,    10,    44,    48,\n",
            "           506,  3226, 32370,  2292,   636,     4,    17,    46,     2,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,    17,    48,   261,     5,  1025,     6,    52,    70,  5281,\n",
            "            37,    16,    10, 21068,     6,    14,    37,    16, 36236,  9997,\n",
            "           542, 26505,    13,    42,     6,    37,    17,    27,    29,   269,\n",
            "          1099,    23,    42,     6,     8,    14,    37,   473,    45,    33,\n",
            "         38187,   102,    17,    27,    29,   275,  3168,  1555,    52,  5281,\n",
            "            37,    17,    27,    29,    95,   856,  3226, 32370,  5373,     6,\n",
            "            17,    46,   512,   338,   982,    11,     5,   569,     4,     2,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   118,   206,    42,  7304, 12574,  1626,    86,  1495,   142,\n",
            "            24,  1326,  2422,   793,     6,    53,   939,    17,    27,   119,\n",
            "         24224,    24,    17,    27,    29,    31, 11133,    11,     5,  1084,\n",
            "          5114,    17,    27,    29, 17298,    30,     5, 28716,     6,    53,\n",
            "           939,   115,    28,  1593,     6,  1169,   169,     6,    24,    16,\n",
            "          1256,   856,  3226, 32370,   444,   375,    63,  1331,    12,  1409,\n",
            "          1248,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   113,  7049,   154,    42,   804,    21,     5, 11111,   631,\n",
            "           142,     7,    28,  5322,     6,   939,   437,   856,  3226, 32370,\n",
            "          8265,    60,    37,  4529,    11,     5,   569,  8194,     4,     2,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "word fucked num_sent 10\n",
            "80\n",
            "tensor([[    0, 26692,     5,   129,   631,    47,   269,    64,   109,    25,\n",
            "            10,  1275,  8674,  6047,    35,  4603,  3140,  7969,    35,  3880,\n",
            "            10,  1099,  6328,    13,    39,  1037,   756,    30,  4142,   145,\n",
            "           350, 42647,    62,   190,     7,   310,    13,  2342,   368,  4347,\n",
            "           194,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   118,   206,    52,   300, 42647,    15,    42,     6,    47,\n",
            "          1669,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,  1694,   619,    42,   169,   142,    52,    25,   390,     8,\n",
            "          2182, 28072,  2550,  5450,    32,  4446,    30,  2313,     8, 42647,\n",
            "            62,  3959,  4502,     7,    28,    55,    11,  2842,    19,     5,\n",
            "          3722,   782,     8,  1072,     9,   643,     6,     7,   694,  3722,\n",
            "           323,    13,    70,   167,   198,   201,     4,     2,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,  8877,   172,  1411,    15,     7,  8745, 16132,     7,  5486,\n",
            "            49, 30883,    19, 18341,    51,   216,    54,    33,  1380,    11,\n",
            "         36712,     6,     8,   190,  6990,  7998,   453,     7,    44,    48,\n",
            "         16111,   292,   728,    31,  3859,    17,    27,    29,  8567,   563,\n",
            "             7,  1067,    59,   141, 42647,    62,    42,    16,    19,    49,\n",
            "           521,     4,    17,    46,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   627, 39418,   578,    29, 11918,    14,  2085,    37,   938,\n",
            "            17,    27,    90,   198,   615,     8,   115,    33,  2327,    39,\n",
            "         26280,   657,    10,   410,   357,  1328,     5,   750,     9, 30515,\n",
            "             6,    84, 30722,  9069,     8,  1076,   119, 25529,  1150,  2327,\n",
            "          2212,  3553, 46806,    14,    37,   429,    33, 42647,    62,    39,\n",
            "           408,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0, 13751,  1035,     6,   939,   439,   149,    41, 11522,  9330,\n",
            "            14,  1249,    62,   269, 12101,    13,   162,     8,  5700, 42647,\n",
            "           162,    62,   269,  7340,   528,     7,  2536,   474,   743,    25,\n",
            "           157,    25,    97,   383,     4,     2,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   267,  1728, 15657, 29565,     5,   939,    33,     7,   109,\n",
            "            42,   142,   939, 16112,   120,    66,     9,   127,  2198, 42647,\n",
            "            62,   301,  2048,     4,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   700,   174,   201,   103,  6516,  8574,    59,     5,  1443,\n",
            "           708,     9,    39,   985,  1245,    11,     5,   515,     9,    10,\n",
            "          1926,   449, 24452, 11307,     6,     8,   141,    51,    32,  1256,\n",
            "           203, 42647,   114,     5,  1926,   473,  2845,     7,   283,   159,\n",
            "            49,   169,     4,     2,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0, 39763,     9,    42,    74,    28,   678,   114,    52,   399,\n",
            "            75,    33,    10, 42647,    62, 20146,    19,  2015,   924,     4,\n",
            "            93,   524,  5219, 34831,  1069,   838,   594,  3281, 38198,  1069,\n",
            "            43,   842,  3320, 22542,   973,     6,   336,     2,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,   118,  2281,    44,    48,  8396,  6620,    17,    46,     6,\n",
            "            44,    48,  3785,  8823,   116,    17,    46,     6,     8,    44,\n",
            "            48,  9178,   171,  3591,    11,   865,   116,    17,    46,     6,\n",
            "            13, 25157,     9,     6,    44,    48,   338,    12,   139,    12,\n",
            "           298,    17,    46,     6,    44,    48,  6025,    21,  6344,   328,\n",
            "            17,    46,     6,     8,   127,  1081,  2674,     6,    44,    48,\n",
            "          6968, 42647,    62,   328,    17,    46,     4,     2,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "word igger num_sent 10\n",
            "90\n",
            "tensor([[    0,   627, 13403,  4715,   219,     9, 10512, 15474, 31962,  4179,\n",
            "           102,     6,     5, 31762,    78,  2654,  1269,     9,  2764,  2977,\n",
            "             6,    33,  6075,    41,  9664,    31,     5,  2051,   821, 11089,\n",
            "           884,   253,   102,   449, 11867,     6,    54,   373,     5, 26652,\n",
            "          9724, 45215, 22211,  6132,    10,   128,   282, 41956,   108,    11,\n",
            "            10,  7159,  8018,     4,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0, 39563,     7, 37958, 17145,    12, 30056, 23893,  7458,  1688,\n",
            "          2086,     7,  1759,    12, 27275, 26232, 25605,   571,  1236,  6909,\n",
            "             6,   394,   218,  5618, 20125,    34,  2468,   160,     5,   559,\n",
            "          6305,     9,   402,    98,  4023, 39890, 35335,    14,   190,     5,\n",
            "         12479, 24890,  6219,    29,    32,   122, 32299,  4543, 41956,   154,\n",
            "            23,   123,     4,     2,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0, 48926,  3369, 27024, 14917,    29,   158,     7,   291,   498,\n",
            "             6,   341,    44,   711,   282,    17,    27,  2136,   350,    35,\n",
            "           809, 12984,     6,   340, 29459,  1236, 21347,   601,     6,  3788,\n",
            "             6,   588,  9910,  1766,     8,  1087,  3741, 10528,   341,   295,\n",
            "         41956,    77,  4904,    19,   951,    11,     5,   909,   435,     2,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,  2028, 39695,  4178,  6704,   117,  3952,   228,   354,    21,\n",
            "           393,    98, 33472,  1342,    87,    77,    79,  1602,   141,    24,\n",
            "          1299,     7,    28,   373,    10,    44,    48,   282, 41956,    17,\n",
            "            46,    30,    10,  2598,  8340,     4,     2,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0, 24139, 20125,    17,    27,    29,  6615,    13,   201,  1921,\n",
            "           937,    21,   683,  1238,     9,  1765,    10,   909,   781,    11,\n",
            "          1076, 46947,    10,    44,    48,   282, 41956,    17,    46,     6,\n",
            "             8,   172,   851,    10,  3950,  8257,     7,     5,   201, 22437,\n",
            "            77, 29029,    59,     5, 10069,     4,     2,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,  9226,  2092,     7,    28,    11,  1263,     7,  6124,     9,\n",
            "          8222,    13,   634,     5,  2136,    44,   711,   282, 41956,     4,\n",
            "            17,    27,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,  9178,  6294,     6,    11,   171,  1319,     5, 27857,    16,\n",
            "             5,  2297,    12,  1208,    44,    48,   282, 41956,    17,    46,\n",
            "             6,    10,  1385,   341,     7, 39454,  1496,     6, 13058,   877,\n",
            "             6, 11809,     8,  2134,    10,   333,     9,    97,  1050, 14766,\n",
            "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,  9442,   373,    10,    44,    48,   282, 41956,    17,    46,\n",
            "            30,    10,  1104,   621,    16,     6,  9574,     6,  1085,    92,\n",
            "             7,   162,    36,   118,    33,  7409,    71,    70,   322,     2,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0,  8310,    52,    33,  1652,     9,    82,    11,  6845,   537,\n",
            "          3246, 16600,    44,    48,   282, 41956,    17,    46,    25,  2851,\n",
            "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "tensor([[    0, 14746,   939,    21,   365,   107,   793,     6,   939,    21,\n",
            "           373,    10,   295, 41956,    23,    10,  3757,  2797,  1400,    30,\n",
            "            10,  2792, 12873,    54,   802,   127,   964,     8,   939,    58,\n",
            "          9460,    31,   123,    77,   411,    50,    98,     9,   201,  2867,\n",
            "            39,  1400,    71,  1349,  1524,     4,     2,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1]])\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt6NSgw8OQMA",
        "outputId": "39d64550-8570-4053-888f-e92a801d4df8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        }
      },
      "source": [
        "ev = [e/count*100 for e in ev]\n",
        "ev1 = ev\n",
        "\n",
        "first_pcs = [f[0] for f in ev1]\n",
        "print('First PCs', first_pcs)\n",
        "plotVariance(first_pcs, title='Debiased Roberta - First PC contributions')\n",
        "\n",
        "second_pcs = [f[1] for f in ev1]\n",
        "print('Second PCs', second_pcs)\n",
        "plotVariance(second_pcs, title='Debiased Roberta - Second PC contributions')\n",
        "\n",
        "third_pcs = [f[2] for f in ev1]\n",
        "print('Third PCs', third_pcs)\n",
        "plotVariance(third_pcs, title='Debiased Roberta - Third PC contributions')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First PCs [100.0, 28.981518, 48.27066, 47.82793, 47.344997, 46.571667, 46.32476, 46.679157, 46.33167, 46.465862, 47.43251, 46.4929, 46.029984]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Second PCs [7.08202e-13, 14.723998, 4.4016786, 3.9982092, 4.285382, 5.0628886, 4.3898115, 5.1879964, 5.7801924, 5.4304886, 5.197697, 5.760583, 5.7847967]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Third PCs [3.5527137e-13, 5.3286114, 2.8925402, 2.838135, 2.9933295, 2.9538424, 3.0003874, 3.191889, 2.934276, 3.2050614, 2.8345983, 2.9785028, 3.4307387]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHJpMDGBgAAc"
      },
      "source": [
        "**Normal GPT2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STSyuXNiOQlm",
        "outputId": "5407b153-3e0a-4bd4-c658-afba6bd5d671",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "toxic_words = ht['Word'][:num_words]\n",
        "ev = [0]*13\n",
        "count = 0\n",
        "# find toxic words and their sentences\n",
        "for word in toxic_words:\n",
        "  \n",
        "  sents = wsentTox[word][:num_sents]\n",
        "  print('word', word, 'num_sent', len(sents))\n",
        "  sflag = False\n",
        "  for sent in sents:\n",
        "    if count % 10 == 0: print(count)\n",
        "    # encoded_text = tokenizer(sent)\n",
        "    encoded_text = tokenizer.encode_plus(\n",
        "        sent, add_special_tokens=True, truncation=True,\n",
        "        max_length=256, padding='max_length',\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt')\n",
        "    tox, attn_masks = encoded_text['input_ids'], encoded_text['attention_mask']\n",
        "    ntox = tox.clone()\n",
        "    tokens = list([tokenizer.convert_ids_to_tokens(i) for i in ntox][0])\n",
        "    tokens = [tok[1:] if tok[0] == 'Ä ' else tok for tok in tokens]\n",
        "    try:\n",
        "      idx = tokens.index(word)\n",
        "    except:\n",
        "      print('PROBLEM!')\n",
        "      # print(tokens)\n",
        "      print(sent)\n",
        "      continue\n",
        "      # sflag = True\n",
        "      # break\n",
        "\n",
        "    ntox[0][idx] = 0\n",
        "\n",
        "    encoded_T = {\n",
        "        \"input_ids\": tox,\n",
        "        \"attention_mask\": attn_masks\n",
        "    }\n",
        "    encoded_NT = {\n",
        "        \"input_ids\": ntox,\n",
        "        \"attention_mask\": attn_masks\n",
        "    }\n",
        "    principal_components, exp_variance = run_roberta_algorithm(encoded_T, encoded_NT, layerRoberta, debias=False)\n",
        "\n",
        "    for i in range(13):\n",
        "      ev[i] += exp_variance[i]\n",
        "    count += 1\n",
        "\n",
        "  if sflag:\n",
        "    break\n",
        "print(count)\n",
        "# print('ev[0]', ev[0])\n",
        "# todo: Use BERTForSentenceClassification then check the classifier hidden output\n",
        "\n",
        "# a = num_sent x 768\n",
        "# b = 2 x 768 PCs\n",
        "# inner = a . bT -> num_sent x 2\n",
        "# inner . b -> num_sent x 768\n",
        "\n",
        "\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word pussy num_sent 10\n",
            "0\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "word whore num_sent 10\n",
            "10\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "word bitch num_sent 10\n",
            "20\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "word fuck num_sent 10\n",
            "30\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "word asshole num_sent 10\n",
            "40\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "word slut num_sent 10\n",
            "50\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "word fucking num_sent 10\n",
            "60\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "word cking num_sent 10\n",
            "70\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "word fucked num_sent 10\n",
            "80\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "word igger num_sent 10\n",
            "90\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "inp_t torch.Size([1, 256]) atn_t torch.Size([1, 256])\n",
            "u[0] torch.Size([1, 256, 768])\n",
            "D[0] torch.Size([1, 256, 768])\n",
            "PC[0] torch.Size([256, 768]) ev[0] (256,)\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uclPuC_PgHQy",
        "outputId": "c96e5d00-e39b-4f61-bec2-5d0658916840",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        }
      },
      "source": [
        "ev = [e/count*100 for e in ev]\n",
        "ev2 = ev\n",
        "\n",
        "first_pcs = [f[0] for f in ev2]\n",
        "print('First PCs', first_pcs)\n",
        "plotVariance(first_pcs, title='Normal Roberta - First PC contributions')\n",
        "\n",
        "second_pcs = [f[1] for f in ev2]\n",
        "print('Second PCs', second_pcs)\n",
        "plotVariance(second_pcs, title='Normal Roberta - Second PC contributions')\n",
        "\n",
        "third_pcs = [f[2] for f in ev2]\n",
        "print('Third PCs', third_pcs)\n",
        "plotVariance(third_pcs, title='Normal Roberta - Third PC contributions')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First PCs [100.0, 83.37503, 71.67365, 59.544228, 55.308254, 54.80538, 54.887547, 53.373356, 52.425564, 52.03517, 52.891262, 55.0673, 52.09275]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Second PCs [7.08202e-13, 6.469295, 11.857852, 16.82483, 19.168299, 18.877048, 19.284304, 19.960276, 20.263216, 19.86512, 18.9958, 17.295881, 16.06329]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Third PCs [3.5527137e-13, 2.9136376, 5.1076584, 6.7143126, 7.213304, 7.2978625, 7.0799136, 7.3865833, 7.359327, 7.474658, 7.4385514, 6.942851, 6.8356447]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9p6Fy21gOI8",
        "outputId": "907bf1f3-beb9-476c-8469-d5e2f018f880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "first_pcs = [f[0] for f in ev1]\n",
        "second_pcs = [f[1] for f in ev1]\n",
        "third_pcs = [f[2] for f in ev1]\n",
        "\n",
        "x = range(len(first_pcs))\n",
        "plt.plot(x, first_pcs)\n",
        "plt.plot(x, second_pcs)\n",
        "plt.plot(x, third_pcs)\n",
        "plt.title(\"Debiased Roberta\")\n",
        "plt.legend(['First PCs', 'Second PCs', 'Third PCs'])\n",
        "plt.show()\n",
        "\n",
        "first_pcs = [f[0] for f in ev2]\n",
        "second_pcs = [f[1] for f in ev2]\n",
        "third_pcs = [f[2] for f in ev2]\n",
        "\n",
        "x = range(len(first_pcs))\n",
        "plt.plot(x, first_pcs)\n",
        "plt.plot(x, second_pcs)\n",
        "plt.plot(x, third_pcs)\n",
        "plt.title(\"Normal Roberta\")\n",
        "plt.legend(['First PCs', 'Second PCs', 'Third PCs'])\n",
        "plt.show()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "425X1VJEiL9G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}